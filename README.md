# üìà Previs√£o de Churn de Clientes com PySpark

## üéØ Objetivo do Projeto

O objetivo deste projeto √© desenvolver um modelo de Machine Learning robusto, utilizando Apache Spark, para prever a probabilidade de um cliente cancelar seu servi√ßo (churn). A an√°lise e modelagem foram feitas sobre uma base de dados de marketing, demonstrando um fluxo de trabalho completo de ponta a ponta, desde o pr√©-processamento dos dados at√© a otimiza√ß√£o de hiperpar√¢metros e a aplica√ß√£o do modelo final.

## üìä Dataset

O conjunto de dados utilizado cont√©m informa√ß√µes demogr√°ficas e de contrato de clientes de uma empresa de telecomunica√ß√µes. Ele est√° dispon√≠vel neste reposit√≥rio como um arquivo compactado.

* **Link para os dados:** [base de dados.zip](base%20de%20dados.zip)

## üíª Tecnologias Utilizadas

* **Apache Spark (PySpark):** Para processamento distribu√≠do e modelagem de Machine Learning.
* **Python 3:** Linguagem de programa√ß√£o principal.
* **Jupyter Notebook:** Ambiente de desenvolvimento interativo.
* **Pandas:** Para a cria√ß√£o e exibi√ß√£o de tabelas comparativas de resultados.

## üöÄ Metodologia

O projeto foi estruturado seguindo as melhores pr√°ticas de ci√™ncia de dados, cobrindo as seguintes etapas:

1.  **An√°lise Explorat√≥ria e Pr√©-processamento:** Carregamento dos dados, verifica√ß√£o do balanceamento da vari√°vel alvo (`Churn`) e an√°lise inicial dos tipos de dados.
2.  **Engenharia de Features:** Transforma√ß√£o de vari√°veis categ√≥ricas (bin√°rias e multinomiais) em formato num√©rico atrav√©s de t√©cnicas de binariza√ß√£o e dummiza√ß√£o (`pivot`).
3.  **Modelagem:** Treinamento de tr√™s algoritmos de classifica√ß√£o distintos para estabelecer uma linha de base de performance:
    * Regress√£o Log√≠stica
    * √Årvore de Decis√£o
    * Random Forest
4.  **Otimiza√ß√£o de Hiperpar√¢metros:** Utiliza√ß√£o de `CrossValidator` e `ParamGridBuilder` para realizar o *tuning* dos modelos de √Årvore de Decis√£o e Random Forest, buscando a melhor combina√ß√£o de par√¢metros para maximizar a performance.
5.  **Avalia√ß√£o Centralizada:** Cria√ß√£o de uma fun√ß√£o (`gerar_relatorio_avaliacao`) para avaliar de forma padronizada todos os modelos, gerando a matriz de confus√£o e as principais m√©tricas.
6.  **Compara√ß√£o e Sele√ß√£o do Melhor Modelo:** Gera√ß√£o de uma tabela comparativa final com os resultados de todos os modelos para selecionar o de melhor performance.
7.  **Aplica√ß√£o do Modelo Final:** Demonstra√ß√£o pr√°tica do uso do modelo selecionado para prever o churn de um novo cliente hipot√©tico.

## üîß Como Executar o Projeto

Para executar este projeto em seu ambiente local ou na nuvem (como Google Colab), siga os passos abaixo:

1.  Clone ou fa√ßa o download deste reposit√≥rio.
2.  Extraia o arquivo `base de dados.zip` para obter o arquivo `dados_clientes.csv`.
3.  Certifique-se de que seu ambiente tenha o PySpark e o Pandas instalados.
    ```bash
    pip install pyspark pandas
    ```
4.  Abra o notebook `previsao_churn.ipynb` e execute as c√©lulas sequencialmente.

## üèÜ Resultados

O modelo final, um **Random Forest Classifier com hiperpar√¢metros otimizados**, alcan√ßou a melhor performance na previs√£o de churn, com uma **Acur√°cia de 81.95%** e um **F1-Score de 0.8246** nos dados de teste.

### Tabela Comparativa dos Modelos

A imagem abaixo resume a performance de todos os modelos avaliados neste projeto.

![Tabela de Resultados dos Modelos](resultados_modelos.png)

## üôè Agradecimentos

Este projeto foi desenvolvido como parte do curso **Spark: modelos de classifica√ß√£o** da [Alura](https://www.alura.com.br/). Gostaria de agradecer a toda a equipe da Alura pelo excelente conte√∫do e, em especial, ao tutor **Igor Nascimento Alves** pelo suporte e mentoria.

## Contato

**Sthefanie Otaviano**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](http://linkedin.com/in/sthefanie-ferreira-de-s-d-otaviano-976a59206)
